---
title: "Practical Machine Learning - Course Project"
output: html_document
author: "Caoimhe Boyle"
---

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

The goal of this analysis is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, who were asked to perform barbell lifts correctly and incorrectly in 5 different ways, to predict the manner in which the particpant did the exercise. This exercise manner is indicated by the `classe` variable 

### Data Preprocessing

The data provided is read in to R as shown below, with any empty fields being replaced with `NA`.

```{r}
training <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
testing <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
```

On inspection of the data, over half the columns contained only `NA` values, which are of no use in training or testing a model, so these columns are removed. The first seven columns of the remaining data sets contain information on the user and the time the exercise took place, which again are not needed for this analysis as we want to predict using accelerometer readings. These seven columns are also removed from both training and testing, as shown below. 

```{r}
training <- training[, colSums(is.na(training)) == 0] 
training <- training[ , -(1:7)]

testing <- testing[, colSums(is.na(testing)) == 0] 
testing <- testing[ , -(1:7)]
```

This leaves us with a training data set with 19622 rows and 53 columns (52 accelerometer readings and the `classe` variable), and a testing data set with 20 rows and 53 columns. 

### Cross Validation

To make use of cross validation, we split the training set on the `classe` variable. 

```{r}
library(caret)
inTrain <- createDataPartition(y = training$classe, p = 0.7, list = F)
trainSet <- training[inTrain,]
testSet <- training[-inTrain,]
```

### Model Building

Using the `trainSet`, we build a model using the Random Forests method. 

```{r}
control <- trainControl(method = "cv", 5)
model <- train(classe ~ ., method = "rf", data = trainSet, trControl = control, ntree = 200)
model
```

We can then make predictions on the validation set, and create a confusion matrix to test the accuracy of the model. 

```{r}
predictions <- predict(model, testSet)
confusionMatrix(testSet$classe, predictions)
```

Using this confusion matrix, we can calculate the out of sample error. 

```{r}
CMTable <- table(testSet$classe, predictions)
outOfSampleError <- 1 - (sum(diag(CMTable))/ length(predictions))
outOfSampleError
```

I am satisfied with the accuracy of the random forests model, as shown in the `Confusion Matrix and Statistics`, and so use this model to predict the `classe` variable on the initial test set.

```{r}
answer_predictions <- predict(model, testing)
answer_predictions
```

### Submitting Files

The following code, provided in the assignment, takes the final predictions and writes each one to a text file, ready for submission to Coursera. 

```{r}
pml_write_files = function(x) {
     n = length(x)
     for(i in 1:n) {
         filename = paste0("problem_id_", i, ".txt")
         write.table(x[i], file=filename, quote=FALSE, row.names=FALSE, col.names=FALSE)
     }
 }

pml_write_files(answer_predictions)
```

